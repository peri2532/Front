"""
ê¸°ì¡´ CSV íŒŒì¼ ë³¸ë¬¸ ë³´ì™„ í¬ë¡¤ëŸ¬
ë³¸ë¬¸ì´ ì—†ëŠ” ê¸°ì‚¬ë§Œ ë‹¤ì‹œ í¬ë¡¤ë§í•˜ì—¬ ì—…ë°ì´íŠ¸
ì‹¤íŒ¨ ì‚¬ìœ ë³„ í†µê³„ í¬í•¨
"""

import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from datetime import datetime
import os
import re
import glob

class ContentUpdater:
    def __init__(self):
        self.options = webdriver.ChromeOptions()
        self.options.add_argument('--start-maximized')
        self.options.add_argument('--disable-blink-features=AutomationControlled')
        self.options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.options.add_experimental_option('useAutomationExtension', False)
        self.options.add_argument('--page-load-strategy=eager')

        self.driver = webdriver.Chrome(options=self.options)
        self.driver.set_page_load_timeout(8)

    def extract_article_content(self, url, max_retries=2):
        """ê¸°ì‚¬ íŽ˜ì´ì§€ì—ì„œ ë³¸ë¬¸ 1~3ì¤„ ì¶”ì¶œ"""
        original_window = self.driver.current_window_handle

        for attempt in range(max_retries):
            try:
                self.driver.execute_script(f"window.open('{url}', '_blank');")
                WebDriverWait(self.driver, 3).until(lambda d: len(d.window_handles) > 1)
                self.driver.switch_to.window(self.driver.window_handles[-1])
                time.sleep(1)

                content_selectors = [
                    'div#dic_area', 'div#articleBodyContents', 'div.article_body',
                    'div#articeBody', 'div.article_view', 'div.article-body',
                    'div.news_body', 'div.view_body', 'div#news-body-area',
                    'div.news-article-body', 'article', 'div[itemprop="articleBody"]',
                    'div.article-text', 'div.article', 'div.content', 'div.news_content',
                ]

                content_text = ""

                for selector in content_selectors:
                    try:
                        content_elem = WebDriverWait(self.driver, 2).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                        )
                        text = content_elem.text.strip()
                        if text and len(text) > 50:
                            content_text = text
                            break
                    except:
                        continue

                if content_text:
                    lines = []
                    for line in content_text.split('\n'):
                        line = line.strip()
                        if len(line) < 10:
                            continue
                        if 'ê¸°ìž' in line and len(line) < 30:
                            continue
                        if re.match(r'^\d{4}[-./]\d{1,2}[-./]\d{1,2}', line):
                            continue
                        if line.startswith('[') and line.endswith(']'):
                            continue
                        if 'ë¬´ë‹¨ì „ìž¬' in line or 'ìž¬ë°°í¬' in line:
                            continue
                        lines.append(line)
                        if len(lines) >= 3:
                            break
                    result = ' '.join(lines[:3])
                    if len(result) > 300:
                        result = result[:300] + '...'
                    self.driver.close()
                    self.driver.switch_to.window(original_window)
                    return result

                self.driver.close()
                self.driver.switch_to.window(original_window)
                return ""

            except:
                try:
                    if len(self.driver.window_handles) > 1:
                        self.driver.close()
                    self.driver.switch_to.window(original_window)
                except:
                    pass
                if attempt < max_retries - 1:
                    continue
                else:
                    return ""

        return ""

    def update_csv_file(self, csv_path):
        """CSV íŒŒì¼ì˜ ë³¸ë¬¸ ì—†ëŠ” ê¸°ì‚¬ë§Œ í¬ë¡¤ë§í•˜ì—¬ ì—…ë°ì´íŠ¸"""

        print(f"\n{'='*70}")
        print(f"ðŸ“„ íŒŒì¼: {os.path.basename(csv_path)}")
        print(f"{'='*70}")

        try:
            df = pd.read_csv(csv_path)

            if 'content' not in df.columns:
                df['content'] = ''

            missing_content = df['content'].isna() | (df['content'] == '') | (df['content'].astype(str).str.strip() == '')
            missing_count = missing_content.sum()
            total_count = len(df)

            print(f"ðŸ“Š ì „ì²´: {total_count}ê°œ")
            print(f"âœ… ë³¸ë¬¸ ìžˆìŒ: {total_count - missing_count}ê°œ")
            print(f"âŒ ë³¸ë¬¸ ì—†ìŒ: {missing_count}ê°œ")

            if missing_count == 0:
                print(f"âœ“ ëª¨ë“  ê¸°ì‚¬ì— ë³¸ë¬¸ ìžˆìŒ. ìŠ¤í‚µ!")
                return df

            print(f"\nðŸ“ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œìž‘ ({missing_count}ê°œ)")

            success = 0
            fail = 0

            fail_reasons = {
                'url_missing': 0,
                'no_selector_found': 0,
                'load_error': 0,
                'other': 0,
            }

            for idx in df[missing_content].index:
                try:
                    url = str(df.at[idx, 'url']).strip()

                    if not url or url.lower() == 'nan':
                        fail_reasons['url_missing'] += 1
                        fail += 1
                        continue

                    print(f"  [{success + fail + 1}/{missing_count}] í¬ë¡¤ë§ ì¤‘...", end='\r')

                    content = self.extract_article_content(url)

                    if content:
                        df.at[idx, 'content'] = content
                        success += 1
                    else:
                        fail += 1
                        fail_reasons['no_selector_found'] += 1

                except Exception as e:
                    fail += 1
                    error_msg = str(e).lower()
                    if 'timeout' in error_msg or 'chrome' in error_msg or 'load' in error_msg:
                        fail_reasons['load_error'] += 1
                    else:
                        fail_reasons['other'] += 1

                if (success + fail) % 20 == 0:
                    print(f"  [{success + fail}/{missing_count}] ì„±ê³µ: {success}, ì‹¤íŒ¨: {fail}")

                time.sleep(0.3)

            print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"   ì„±ê³µ: {success}ê°œ")
            print(f"   ì‹¤íŒ¨: {fail}ê°œ")

            print(f"\nðŸ“‰ ì‹¤íŒ¨ ì‚¬ìœ  í†µê³„:")
            for reason, count in fail_reasons.items():
                label = {
                    'url_missing': "ðŸ”— ë§í¬ ì—†ìŒ",
                    'no_selector_found': "ðŸ§± ë³¸ë¬¸ íƒœê·¸ ì—†ìŒ",
                    'load_error': "â³ íŽ˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨",
                    'other': "â— ê¸°íƒ€ ì˜ˆì™¸"
                }.get(reason, reason)
                print(f"   {label:<20}: {count}ê±´")

            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"ðŸ’¾ ì €ìž¥ ì™„ë£Œ: {csv_path}")

            return df

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None

    def update_all_files(self, folder_path='naver_news_data', exclude_patterns=None):
        """í´ë” ë‚´ ëª¨ë“  CSV íŒŒì¼ ì—…ë°ì´íŠ¸"""

        if exclude_patterns is None:
            exclude_patterns = ['SKí•˜ì´ë‹‰ìŠ¤', 'ì‚¼ì„±ì „ìž_news', 'í˜„ëŒ€ìžë™ì°¨_news']

        print(f"\nðŸš€ CSV íŒŒì¼ ë³¸ë¬¸ ë³´ì™„ ì‹œìž‘")
        print(f"ðŸ“ í´ë”: {folder_path}")
        print(f"ðŸš« ì œì™¸ íŒ¨í„´: {', '.join(exclude_patterns)}")
        print(f"{'='*70}\n")

        csv_files = glob.glob(f"{folder_path}/*.csv")

        filtered_files = []
        for csv_file in csv_files:
            filename = os.path.basename(csv_file)
            should_exclude = any(filename.startswith(pattern) for pattern in exclude_patterns)
            if should_exclude:
                print(f"â­ï¸  ì œì™¸: {filename}")
            else:
                filtered_files.append(csv_file)

        print(f"\nðŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ: {len(filtered_files)}ê°œ íŒŒì¼")
        for f in filtered_files:
            print(f"   â€¢ {os.path.basename(f)}")

        if not filtered_files:
            print("\nâš ï¸ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print()

        results = {}
        start_time = time.time()

        for i, csv_file in enumerate(filtered_files, 1):
            print(f"\n[{i}/{len(filtered_files)}]")
            df = self.update_csv_file(csv_file)
            results[csv_file] = df

            if i < len(filtered_files):
                print(f"\nâ³ ë‹¤ìŒ íŒŒì¼ê¹Œì§€ 3ì´ˆ ëŒ€ê¸°...")
                time.sleep(3)

        elapsed_time = time.time() - start_time

        print(f"\n{'='*70}")
        print(f"ðŸŽ‰ ì „ì²´ ìž‘ì—… ì™„ë£Œ!")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
        print(f"{'='*70}\n")

        print("ðŸ“Š ìµœì¢… ê²°ê³¼:")
        for csv_file, df in results.items():
            if df is not None:
                filename = os.path.basename(csv_file)
                total = len(df)
                with_content = df['content'].notna().sum()
                print(f"  âœ“ {filename}: {with_content}/{total}ê°œ ë³¸ë¬¸ ìžˆìŒ")
            else:
                print(f"  âœ— {os.path.basename(csv_file)}: ì‹¤íŒ¨")

        print(f"\nðŸ’¾ ì €ìž¥ ìœ„ì¹˜: {folder_path}/")

    def close(self):
        self.driver.quit()


if __name__ == "__main__":
    print("="*70)
    print("ðŸ“ ê¸°ì¡´ CSV íŒŒì¼ ë³¸ë¬¸ ë³´ì™„ í¬ë¡¤ëŸ¬")
    print("="*70)
    print("âœ… ë³¸ë¬¸ ìžˆëŠ” ê¸°ì‚¬: ìœ ì§€")
    print("âŒ ë³¸ë¬¸ ì—†ëŠ” ê¸°ì‚¬: ë‹¤ì‹œ í¬ë¡¤ë§")
    print("ðŸš« ì œì™¸: SKí•˜ì´ë‹‰ìŠ¤, ì‚¼ì„±ì „ìž_news, í˜„ëŒ€ìžë™ì°¨_newsë¡œ ì‹œìž‘í•˜ëŠ” íŒŒì¼")
    print("="*70)

    folder = input("\nCSV íŒŒì¼ì´ ìžˆëŠ” í´ë” ê²½ë¡œ (ì—”í„°=naver_news_data): ").strip()
    if not folder:
        folder = "naver_news_data"

    response = input(f"\n'{folder}' í´ë”ì˜ íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")

    if response.lower() != 'y':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        exit()

    updater = ContentUpdater()

    try:
        exclude_patterns = ['SKí•˜ì´ë‹‰ìŠ¤', 'ì‚¼ì„±ì „ìž_news', 'í˜„ëŒ€ìžë™ì°¨_news']
        updater.update_all_files(
            folder_path=folder,
            exclude_patterns=exclude_patterns
        )
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìž ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        updater.close()
        print("\nðŸ‘‹ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")
