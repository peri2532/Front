import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import yfinance as yf
import glob

# âœ… 1. ìˆ˜ì§‘í•œ CSV íŒŒì¼ë“¤ í†µí•©
def merge_news_csvs():
    """ëª¨ë“  ê¸°ì—… ë‰´ìŠ¤ CSVë¥¼ í•˜ë‚˜ë¡œ í†µí•©"""
    all_files = glob.glob("*_news_*.csv")
    
    if not all_files:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return None
    
    df_list = []
    for file in all_files:
        df = pd.read_csv(file, encoding='utf-8-sig')
        df_list.append(df)
    
    merged_df = pd.concat(df_list, ignore_index=True)
    print(f"âœ… ì´ {len(merged_df)}ê°œ ë‰´ìŠ¤ í†µí•© ì™„ë£Œ")
    
    return merged_df

# âœ… 2. ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
def get_stock_data(ticker_symbol, start_date, end_date):
    """í•œêµ­ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        stock = yf.download(ticker_symbol, start=start_date, end=end_date, progress=False)
        return stock
    except Exception as e:
        print(f"âŒ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return None

# âœ… 3. ë‰´ìŠ¤-ì£¼ê°€ ë ˆì´ë¸”ë§ (ì™„ì „ ìˆ˜ì •)
def create_labeled_dataset(news_df):
    """ë‰´ìŠ¤ ë°œí‘œ í›„ ì£¼ê°€ ë³€ë™ì„ ê¸°ì¤€ìœ¼ë¡œ ë ˆì´ë¸” ìƒì„±"""
    
    ticker_map = {
        "ì‚¼ì„±ì „ì": "005930.KS",
        "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS",
        "LGì—ë„ˆì§€ì†”ë£¨ì…˜": "373220.KS",
        "í˜„ëŒ€ì°¨": "005380.KS",
        "ê¸°ì•„": "000270.KS",
        "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": "207940.KS",
        "ì…€íŠ¸ë¦¬ì˜¨": "068270.KS",
        "ì¹´ì¹´ì˜¤": "035720.KS",
        "ë„¤ì´ë²„": "035420.KS",
        "POSCOí™€ë”©ìŠ¤": "005490.KS"
    }
    
    labeled_data = []
    
    for company in news_df['ê¸°ì—…'].unique():
        print(f"\nğŸ” [{company}] ë ˆì´ë¸”ë§ ì‹œì‘...")
        
        company_news = news_df[news_df['ê¸°ì—…'] == company].copy()
        ticker = ticker_map.get(company)
        
        if not ticker:
            print(f"  âš ï¸ í‹°ì»¤ ì‹¬ë³¼ ì—†ìŒ")
            continue
        
        # ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        stock_data = get_stock_data(ticker, start_date, end_date)
        
        if stock_data is None or stock_data.empty:
            print(f"  âš ï¸ ì£¼ê°€ ë°ì´í„° ì—†ìŒ")
            continue
        
        success_count = 0
        
        # ê° ë‰´ìŠ¤ë³„ ë ˆì´ë¸”ë§
        for idx, row in company_news.iterrows():
            try:
                # ë‰´ìŠ¤ ë‚ ì§œ íŒŒì‹± (ì—¬ëŸ¬ í˜•ì‹ ì‹œë„)
                date_str = row['ë‚ ì§œ']
                
                try:
                    # RFC 2822 í˜•ì‹ (Google News RSS)
                    news_date = pd.to_datetime(date_str, format='%a, %d %b %Y %H:%M:%S %Z', errors='coerce')
                    if pd.isna(news_date):
                        # ISO í˜•ì‹
                        news_date = pd.to_datetime(date_str, errors='coerce')
                except:
                    news_date = pd.to_datetime(date_str, errors='coerce')
                
                if pd.isna(news_date):
                    continue
                
                # ì‹œê°„ëŒ€ ì œê±°
                if news_date.tzinfo is not None:
                    news_date = news_date.tz_localize(None)
                
                # ë‚ ì§œë§Œ ì¶”ì¶œ (ì‹œê°„ ì œê±°)
                news_date_only = news_date.date()
                
                # ì£¼ê°€ ë°ì´í„°ì—ì„œ ë‰´ìŠ¤ ë‚ ì§œ ì´í›„ ë°ì´í„° í•„í„°ë§
                future_mask = stock_data.index.date >= news_date_only
                future_data = stock_data[future_mask]
                
                if len(future_data) < 4:  # ìµœì†Œ 4ê±°ë˜ì¼ í•„ìš”
                    continue
                
                # ê¸°ì¤€ê°€ì™€ 3ê±°ë˜ì¼ í›„ ê°€ê²©
                base_price = float(future_data.iloc[0]['Close'])
                future_price = float(future_data.iloc[3]['Close'])
                
                # ìˆ˜ìµë¥  ê³„ì‚°
                return_3d = ((future_price - base_price) / base_price) * 100
                
                # ë ˆì´ë¸” ìƒì„±
                if return_3d > 2:
                    sentiment_label = "ê¸ì •"
                    trade_signal = "ë§¤ìˆ˜"
                elif return_3d < -2:
                    sentiment_label = "ë¶€ì •"
                    trade_signal = "ë§¤ë„"
                else:
                    sentiment_label = "ì¤‘ë¦½"
                    trade_signal = "ê´€ë§"
                
                labeled_data.append({
                    'ê¸°ì—…': company,
                    'í‹°ì»¤': ticker,
                    'ì œëª©': row['ì œëª©'],
                    'ë³¸ë¬¸ìš”ì•½': row['ë³¸ë¬¸ìš”ì•½'],
                    'ë‚ ì§œ': news_date,
                    '3ì¼ìˆ˜ìµë¥ ': round(return_3d, 2),
                    'ê°ì„±ë ˆì´ë¸”': sentiment_label,
                    'ê±°ë˜ì‹ í˜¸': trade_signal
                })
                
                success_count += 1
                
            except Exception as e:
                # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ ìƒëµ (ë„ˆë¬´ ë§ìŒ)
                continue
        
        print(f"  âœ… {success_count}ê°œ ë ˆì´ë¸” ì™„ë£Œ")
    
    result_df = pd.DataFrame(labeled_data)
    
    if result_df.empty:
        print("\nâŒ ë ˆì´ë¸”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        print("   ì›ì¸: ë‰´ìŠ¤ ë‚ ì§œê°€ ìµœê·¼ì´ë¼ ì£¼ê°€ ë°ì´í„° ë¶€ì¡±")
        return None
    
    print(f"\n{'='*60}")
    print(f"âœ… ì „ì²´ ë ˆì´ë¸”ë§ ì™„ë£Œ: {len(result_df)}ê°œ")
    print(f"\nğŸ“Š ê°ì„± ë ˆì´ë¸” ë¶„í¬:")
    print(result_df['ê°ì„±ë ˆì´ë¸”'].value_counts())
    print(f"\nğŸ“Š ê±°ë˜ ì‹ í˜¸ ë¶„í¬:")
    print(result_df['ê±°ë˜ì‹ í˜¸'].value_counts())
    print(f"{'='*60}")
    
    return result_df

# âœ… 4. ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ¯ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹œì‘\n")
    
    # 1ë‹¨ê³„: ë‰´ìŠ¤ CSV í†µí•©
    news_df = merge_news_csvs()
    
    if news_df is not None:
        # 2ë‹¨ê³„: ì£¼ê°€ ë°ì´í„°ì™€ ê²°í•©í•˜ì—¬ ë ˆì´ë¸” ìƒì„±
        labeled_df = create_labeled_dataset(news_df)
        
        # 3ë‹¨ê³„: ì €ì¥
        if labeled_df is not None and not labeled_df.empty:
            output_file = f"labeled_news_dataset_{datetime.now().strftime('%Y%m%d')}.csv"
            labeled_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
            
            # 4ë‹¨ê³„: í•™ìŠµìš©/í…ŒìŠ¤íŠ¸ìš© ë¶„ë¦¬
            train_size = int(len(labeled_df) * 0.8)
            train_df = labeled_df.iloc[:train_size]
            test_df = labeled_df.iloc[train_size:]
            
            train_df.to_csv('train_dataset.csv', index=False, encoding='utf-8-sig')
            test_df.to_csv('test_dataset.csv', index=False, encoding='utf-8-sig')
            
            print(f"ğŸ“š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ â†’ train_dataset.csv")
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ â†’ test_dataset.csv")
        else:
            print("\nâŒ ë ˆì´ë¸” ë°ì´í„° ìƒì„± ì‹¤íŒ¨!")
            print("   ë‰´ìŠ¤ê°€ ë„ˆë¬´ ìµœê·¼ì´ë¼ ì£¼ê°€ ë³€ë™ ë°ì´í„°ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")